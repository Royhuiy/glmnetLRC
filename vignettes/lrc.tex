\documentclass{article}

\usepackage[left=1in, top=1in, right=1in, bottom=1in]{geometry}
\usepackage{graphicx, color}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{url}
\usepackage{float}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{framed}
\usepackage{here}
\usepackage{zi4}
\usepackage{color}
\usepackage{Sweave}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\median}{median}


\renewcommand{\baselinestretch}{1.2}

% \VignetteIndexEntry{lrc Example}

\begin{document} 
\input{lrc-concordance}

\title{{\tt lrc}: Logistic regression classification (LRC) with an arbitrary loss function\\}
\author{Landon Sego, Alexander Venzin}
\maketitle

\section{Introduction}

The {\tt lrc} package extends the {\tt glmnet} package by making it possible to train elastic net logistic 
regression classifiers (LRC's) using a customized, discrete loss function.  This allows users to assign unique 
loss values to false positive and false negative errors. This approach was originally implemented to automate the
process of determining the curation quality of mass spectrometry samples. Some of the data documented in 
\cite{thepaper} will be used here to demonstrate how to train your own classifier. The elastic net parameter
estimates are obtained by maximizing a penalized likelihood function. The penalty is essentially a weighted average
of the ridge penalty ($L_2$ norm) and the lasso penalty ($L_1$ norm) of the regression parameters.  This
approach balances feature selection and model simplicity. 

In the sections that follow, we show how to use the {\tt lrc} package to train LRC models, create diagnostic plots,
extract coefficients, predict the binary class of new observations, and summarize the performance of those
predictions. The details of the algorithms used by the package are provided in the Appendix.

\section{Training}

Let's begin by loading the package and the training data:
\begin{Schunk}
\begin{Sinput}
> # Load the package
> library(lrc)
> # Load the VOrbitrap Shewanella QC data
> data(traindata)
> # A view of first two rows and first 12 columns
> traindata[1:2, 1:12]
\end{Sinput}
\begin{Soutput}
      Instrument_Category Instrument Dataset_ID Acq_Time_Start Acq_Length
pt701           VOrbitrap VOrbiETD03     251690     12/31/2011         98
pt702           VOrbitrap VOrbiETD03     251706       1/1/2012         98
                                          Dataset Dataset_Type Curated_Quality
pt701 QC_Shew_11_06_col2A_30Dec11_Cougar_11-10-11      HMS-MSn            good
pt702 QC_Shew_11_06_col2C_30Dec11_Cougar_11-10-11      HMS-MSn            good
      XIC_WideFrac XIC_FWHM_Q1 XIC_FWHM_Q2 XIC_FWHM_Q3
pt701     0.297090     19.3820     21.1900     24.3149
pt702     0.305519     19.3785     21.1812     24.3262
\end{Soutput}
\begin{Sinput}
> # Columns 9 to 96 contain various measures of dataset quality that
> # we will use to predict the "Curated_Quality"
> predictors <- as.matrix(traindata[,9:96])
\end{Sinput}
\end{Schunk}

\noindent We fit the LRC model by calling {\tt glmnetLRC()}, which 
requires a binary response variable, coded
as a {\tt factor}.  The order in which the response variable
is coded is important.  Specifically, the class we want to predict with
the greatest sensitivity should be encoded as the second level. To illustrate how this
is done, consider the Shewanella QC data, where the objective is to be
sensitive to predicting poor datasets.  Hence we code ``poor" last, as follows:
\begin{Schunk}
\begin{Sinput}
> response <- factor(traindata$Curated_Quality,
+                    levels = c("good", "poor"),
+                    labels = c("good", "poor"))
> levels(response)
\end{Sinput}
\begin{Soutput}
[1] "good" "poor"
\end{Soutput}
\end{Schunk}
\noindent Now we must define a discrete loss matrix. For the curation
of dataset quality, predicting ``good" when the dataset is ``poor" is considerably 
worse (Loss = 5) than predicting ``poor" when the dataset
is ``good" (Loss = 1).  Correct predictions receive a penalty of zero loss:

\begin{Schunk}
\begin{Sinput}
> # Define the loss matrix
> lM <- lossMatrix(c("good","good","poor","poor"),
+                  c("good","poor","good","poor"),
+                  c(     0,     1,     5,     0))
> # Observe the structure of the loss matrix
> lM
\end{Sinput}
\begin{Soutput}
           Predicted.good Predicted.poor
Truth.good              0              1
Truth.poor              5              0
\end{Soutput}
\end{Schunk}

To train an elastic net model, the user needs to supply a handful of arguments to {\tt glmnetLRC()}. 
The mandatory arguments are the true class labels, {\tt truthLabels} (which, in this case, is, is the {\tt response} 
object we created above), the matrix of predictor variables, {\tt predictors}, 
and the loss matrix {\tt lossMat}. Noteworthy additional arguments include {\tt tauVec}, a vector of potential 
thresholds $\tau \in (0, 1)$ that are used to dichotomize the predicted probabilities from the logistic regression 
into two class labels; {\tt alphaVec}, a vector of potential values of the elastic net mixing parameter 
$\alpha \in [0, 1]$; {\tt cvFolds}, the number of cross validation folds; and {\tt masterSeed}, which controls 
the partitioning the data into the cross validation folds. Keep in mind that $\alpha$ governs the tradeoff between 
the two regularization penalties. When $\alpha = 0$, $L_2$ regularization (the ridge penalty) is used,
and when $\alpha = 1$, $L_1$ regularization (the lasso penality) is used.

Heavier sampling of {\tt tauVec} or {\tt alphaVec} (i.e., sequences of greater length) leads to 
increased computation time, but more of the parameter space will be sampled, potentially leading to a better 
classifier.  We now train the elastic net logistic regression using restricted values of {\tt tauVec} and 
{\tt alphaVec} and a small number of cross validation replicates, {\tt cvReps}.
\begin{Schunk}
\begin{Sinput}
> # Set the number of cores to be one less than the total available
> ncores <- max(1, parallel::detectCores() - 1)
> # Fit the LRC model with 2 cross validation replicates per core
> lrc_fit <- glmnetLRC(response, predictors, lM, nJobs = ncores,
+                      cvFolds = 5, cvReps = 2 * ncores,
+                      alphaVec = c(1, 0.5), tauVec = c(0.3, 0.5, 0.7),
+                      estimateLoss = TRUE)