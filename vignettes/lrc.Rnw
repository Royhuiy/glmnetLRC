\documentclass{article}

\usepackage[left=1in, top=1in, right=1in, bottom=1in]{geometry}
\usepackage{graphicx, color}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{url}
\usepackage{float}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{framed}
\usepackage{here}
\usepackage{zi4}
\usepackage{color}
\usepackage{Sweave}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\renewcommand{\baselinestretch}{1.2}

% \VignetteIndexEntry{lrc Example}

\begin{document} 
\SweaveOpts{concordance=TRUE}

\title{{\tt lrc}: Logistic regression classification (LRC) with an arbitrary loss function\\}
\author{Landon Sego, Alexander Venzin}
\maketitle

\section{Introduction}

The {\tt lrc} package extends the {\tt glmnet} package by making it possible to train elastic net logistic 
regression classifiers (LRC's) using a customized, discrete loss function.  This allows users to assign unique 
loss values to false positive and false negative errors. This approach was originally implemented to automate the
process of determining the curation quality of mass spectrometry samples. Some of the data documented in 
\cite{thepaper} will be used here to demonstrate how to train your own classifier. The elastic net parameter
estimates are obtained by maximizing a penalized likelihood function. The penalty is essentially a weighted average
of the ridge penalty ($\ell_2$ norm) and the lasso penalty ($\ell_1$ norm) of the regression parameters.  This
approach balances feature selection and model simplicity. 

In the sections that follow, we show how to use the {\tt lrc} package to train LRC models, create diagnostic plots,
extract coefficients, predict the binary class of new observations, and summarize the performance of those
predictions. The details of the algorithms used by the package are provided in the Appendix.

\section{Training}

Let's begin by loading the package and the training data:
% # <<data>>==
% # # Load the package
% # library(lrc)
% # 
% # # Load the VOrbitrap Shewanella QC data
% # data(traindata)
% # 
% # # A view of first five rows and first 12 columns
% # traindata[1:5, 1:12]
% # 
% # # Here we select the predictor variables
% # predictors <- as.matrix(traindata[,9:96])
% # @ 

\noindent We fit the LRC model by calling {\tt LRCglmnet()}, which 
requires a binary response variable, coded
as a {\tt factor}.  The order in which the response variable
is coded is important.  Specifically, the class we want to predict with
the greatest sensitivity should be encoded as the second level. To illustrate how this
is done, consider the Shewanella QC data, where the objective is to be
sensitive to predicting poor datasets.  Hence we code ``poor" last, as follows:
% # <<data1>>=
% # response <- factor(traindata$Curated_Quality,
% #                    levels = c("good", "poor"),
% #                    labels = c("good", "poor"))
% # 
% # levels(response)
% # @ 
\noindent Now we must define a discrete loss matrix. For the curation
of dataset quality, predicting ``good" when the dataset is ``poor" is considerably 
worse (Loss = 5) than predicting ``poor" when the dataset
is ``good" (Loss = 1).  Correct predictions receive a penalty of zero loss:

% <<data2>>=
% lM <- lossMatrix(c("good","good","poor","poor"),
%                  c("good","poor","good","poor"),
%                  c(     0,     1,     5,     0))
% 
% # Observe the structure of the loss matrix
% lM
% @ 

To train an elastic net model, the user needs to supply a handful of arguments to {\tt LRCglmnet()}. 
The mandatory arguments are the true class labels, {\tt truthLabels} (which, in this case, is, is the {\tt response} 
object we created above), the matrix of predictor variables, {\tt predictors}, 
and the loss matrix {\tt lossMat}. Noteworthy additional arguments include {\tt tauVec}, a vector of potential 
thresholds $\tau \in (0, 1)$ that are used to dichotomize the predicted probabilities from the logistic regression 
into two class labels; {\tt alphaVec}, a vector of potential values of the elastic net mixing parameter 
$\alpha \in [0, 1]$; {\tt cvFolds}, the number of cross validation folds; and {\tt masterSeed}, which controls 
the partitioning the data into the cross validation folds. Keep in mind that $\alpha$ governs the tradeoff between 
the two regularization penalties. When $\alpha = 0$, the objective is $\ell_2$ regularization (ridge regression) 
and when $\alpha = 1$, the objective is $\ell_1$ regularization (lasso regression).   

Be advised that heavier sampling of {\tt tauVec} or {\tt alphaVec} (i.e., sequences of greater length) leads to 
increased computation time, but more of the parameter space will be sampled, potentially leading to a better 
classifier. A step by step description of the algorithm that generates the classifier is provided in the appendix.  
We now train the elastic net logistic regression using the default settings for $\tau$ and the number of cross 
validation folds (which is 5) and restricting $\alpha = (0.5, 1)$:
% <<train>>=
% # Set the number of cores to be one less than the total available
% ncores <- max(1, parallel::detectCores() - 1)
% 
% lrc_fit <- LRCglmnet(response, predictors, lM, nJobs = ncores,
%                      alphaVec = c(1, 0.5), tauVec = c(0.3, 0.5, 0.7),
%                      cvReps = 2 * ncores, estimateLoss = TRUE)
% 
% @ 

\noindent The call to {\tt LRCglmnet()} uses cross validation to solve for the optimal parameter settings 
$\left(\alpha, \lambda, \tau\right)$ that minimize the expected loss for the elastic net logistic regression 
classifier. Printing the resulting object shows the median value for the parameters over the cross validation 
replicates, as well as the average and standard deviation of the expected loss that is calculated for each
cross validation replicate.
 
% <<checkdat>>==
% print(lrc_fit)
% @

\noindent We can also extract the coefficients of the logistic regression model that was created using the 
optimal values of $\alpha$ and $\lambda$ (which were shown by the call to the {\\tt print} method above):
% <<getCoef>>==
% coef(lrc_fit)
% @

\section{Prediction}

Now that the classifier has been properly trained and the optimal parameters have been identified, we are 
interested in making predictions for new data observations. This requires the elastic net regression model 
(the output from {\tt LRCglmnet}) and the set of new observations to be predicted, {\tt newdata}.  If true labels 
are available in {\tt newdata}, the column containing these true class labels can be specified via the 
{\tt truthCol} argument. Additionally, one may wish to carry through a subset of the explanatory variables in 
{\tt newdata}.  These columns are indicated using {\tt keepCols}.   True labels are not required to make 
predictions---but they are required to compute performance metrics (sensitivity, specificity, etc.) for the 
elastic net logistic regression model. We begin by testing the classifer on the training data:
% <<predictTrain>>=
% 
% predictTrain <- predict(lrc_fit, traindata, truthCol = "Curated_Quality", keepCols = 1:2)
% 
% # Look at beginning of the predicted data.  Note the extra columns that were kept.
% head(predictTrain)
% 
% # Summarize the peformance of the new classifier in terms of a 
% # variety of metrics:
% summary(predictTrain)
% @
\noindent Note how the sensitivity for detecting poor datsets is considerably better than the specificity. 
These results reflect a loss function that penalizes false negative errors associated with classifying a 
"poor" curation quality as "good" more than false positive errors (classifying a "good" curation quality 
as "poor"). 

\noindent Now let's bring in some new data and examine the performance of the classifier:
% <<predict>>==
% # load the data for testing
% data(testdata)
% 
% # Create table observing the true number of good/poor items 
% with(testdata, table(Curated_Quality))
% 
% # Predict new data
% predictTest <- predict(lrc_fit,testdata,
%                        truthCol = "Curated_Quality")
% 
% # Look at the first few rows
% head(predictTest)
% 
% # Summarize the output of predicting the data we trained on 
% summary(predictTest)
% @ 

\section{Diagnostics}

\noindent Finally, we would like to get a sense of the distribution of the parameters that were chosen 
during the cross validation phase. The {\tt plot} method produces a 3 x 3 scatterplot matrix of the optimal 
triples $\left(\alpha, \lambda, \tau\right)$ associated with the selected regression model from each cross 
validation replicate. The univariate distribution of each parameter is plotted on the diagonal of the 
scatterplot matrix.  Ideally, the distributions of the parameters will be tight over the cross validation 
replicates, indicating that the choice of $\left(\alpha, \lambda, \tau\right)$ is stable regardless of
the particular random partition used for cross-validation.

% \begin{figure}[H]
% \begin{center}
% <<plot, fig=TRUE, width=6, height=4>>=
% plot(lrc_fit)
% @
% \caption{Scatterplot matrix of optimization parameters}
% \end{center}
% \end{figure}

\nocite{*}
\bibliography{lrc}
\bibliographystyle{plain}  

\newpage

\section*{Appendix}
We present in detail the algorithm used by the {\tt lrc} package to identify the optimal parameter estimates
for a logistic regression classifier (LRC) with variables selection implemented by an elastic net.  

We begin by defining a
number of variables.  Let $i = 1,\ldots,N$ index the observations in a training dataset. 
Let $y_i = 1$ indicate that observation $i$ belongs to category ``1" and $y_i = 0$ indicate
that it belongs to category ``0".  Per the logistic regression model, let  
\begin{align}
P(y_i = 1) \equiv \pi_i = \pi(\mathbf{x}_i, \boldsymbol{\beta}) = 
\frac{\exp(\beta_0 + \boldsymbol{\beta}_1^T \mathbf{x}_i)}{1+\exp(\beta_0 + \boldsymbol{\beta}_1^T \mathbf{x}_i)}
\end{align}
\noindent where $\mathbf{x}_i = (x_1, \ldots x_p)^T$ is a vector of predictors, or covariates, that
influence $\pi_i$, $\beta_0$ is an intercept, $\boldsymbol{\beta}_1 = (\beta_1, \ldots, \beta_p)^T$ is a 
vector of  logistic regression coefficients, and for notational convenience, 
$\boldsymbol{\beta} = (\beta_0, \beta_1, \ldots \beta_p)^T$. The estimate of $\boldsymbol{\beta}$ is influenced by 
two other parameters, 
$\alpha$ and $\lambda$.  The value of $\lambda > 0$ controls the weight of the
penalty of the log-likelihoood function, while $\alpha$ controls the mixture of the ridge and lasso penalties.  
The relationship between $\boldsymbol{\beta}$, $\alpha$, and $\lambda$ will be clarified below.

Let $\hat\pi_i \equiv \pi \bigl( \mathbf{x}_i,\hat{\boldsymbol{\beta}}(\alpha,\lambda) \bigr)$ denote the predicted probability 
that $y_i = 1$.  Then, if $\hat\pi_i > \tau$, where $0 < \tau < 1$, the LRC predicts 
that $y_i = 1$.  To streamline the notation, let the predicted class of observation
$i$ be written as $\hat{y}_i \equiv f \bigl( \mathbf{x}_i,\hat{\boldsymbol{\beta}}(\alpha,\lambda),\tau \bigr) = 
I_{(\hat\pi_i > \tau)}$, and $f$ can be though of as the LRC.

For the elastic net, the estimate $\hat{\boldsymbol{\beta}}$ is the $\boldsymbol{\beta}$
that maximizes the penalized log likelihood function:
\begin{align}
\label{eq:penalized_likelihood}
\hat{\boldsymbol{\beta}}(\alpha,\lambda) = \argmax_{\boldsymbol{\beta}} \Biggl[ \ell(\mathbf{x}_i,\boldsymbol{\beta}) - \lambda 
\biggl( \frac{1-\alpha}{2} \sum_{i=1}^p \beta_i^2 + \alpha \sum_{i=1}^p |\beta_i| \biggr) \Biggr]
\end{align}
\noindent where the unpenalized likelihood is given by
\begin{align}
\ell(\mathbf{x}_i,\boldsymbol{\beta}) = \sum_{i=1}^N \bigl[ y_i \log(\pi_i) + (1 - y_i)\log(1-\pi_i) \bigr]
\end{align}
\noindent Parenthetically, $\alpha = 1$ is the lasso penalty, $\alpha = 0$ is the ridge regression penalty,
and $0 < \alpha < 1$ is a mixture of the two. The penalty in \eqref{eq:penalized_likelihood} is the one
specified in the documentation of {\tt glmnet()} in the {\tt glmnet} package.

The optimal values of $\alpha$, $\lambda$, and $\tau$ are obtained by minimizing the risk, or expected loss, of 
the LRC, where the risk is calculated via cross-validation.  Calculating risk requires that we define a discrete 
loss function, $L(y,\hat{y})$ as follows:
\begin{table}[H]
\begin{center}
\begin{tabular}{c|cc}
& $\hat{y} = 0$ & $\hat{y} = 1$ \\
\hline
$y = 0$ & $0$ & $\kappa_0$ \\
$y = 1$ & $\kappa_1$ & $0$ \\
\end{tabular}
\end{center}
\end{table}
\noindent with $\kappa_0 > 0$ and $\kappa_1 > 0$ chosen to reflect the severity of false-positive and 
false-negative errors, respectively.  Setting $\kappa_0 = \kappa_1 = 1$ results in the commonly used 0-1 loss
function.

Cross-validation is accomplished by randomly partitioning the training data into $m$ folds (non-overlapping and
exhaustive subsets), of the training data. The value of $m$ is controlled by the {\tt cvFolds} argument in 
{\tt glmnet()}. Following the presentation of Hastie et al. \cite{Hastie}, let
\begin{align}
\delta:\{1,\ldots,N\} \rightarrow \{1, \ldots, m\}
\end{align}
\noindent map each observation in the training data to one of the folds.
Let $f^{-k} \bigl( \mathbf{x},\hat{\boldsymbol{\beta}}(\alpha,\lambda),\tau \bigr)$ represent the LRC obtained by estimating 
$\boldsymbol{\beta}$ using all the training data except the $k^{\text{th}}$ fold. The 
cross-validation estimate of the risk is given by
\begin{align}
\label{eq:risk}
R(\alpha,\lambda,\tau) = \frac{1}{N}\sum_{i=1}^N L \Bigl(y_i, f^{-\delta(i)} \bigl(\mathbf{x}_i,
\hat{\boldsymbol{\beta}}(\alpha,\lambda),\tau \bigr) \Bigr)
\end{align}
\noindent Note that \eqref{eq:risk} is defined such that each observation in the training data receives 
equal weight. The optimal estimates of $\alpha$, $\lambda$, and $\tau$ are those that minimize the risk:
\begin{align}
\hat\alpha,\hat\lambda,\hat\tau = \argmin_{\alpha,\lambda,\tau} R(\alpha,\lambda,\tau)
\end{align}
In practice, we calculate $(\hat\alpha$, $\hat\lambda$, $\hat\tau)$ by computing \eqref{eq:risk} over an irregular
cube of discrete parameter values, defined by the combination of three vectors:  
$\boldsymbol\alpha \times \boldsymbol\lambda \times \boldsymbol\tau$.
The point in the cube that minimizes the risk becomes the estimate for $(\alpha, \lambda, \tau)$.
The values of $\boldsymbol\alpha$ and $\boldsymbol\tau$ are specified by the {\tt alphaVec} and {\tt tauVec} arguments
of {\tt LRCglmnet()}, respectively.  The values of $\boldsymbol\lambda$ depend on each $\alpha$ and are chosen algorithmically
by {\tt glmnet()}, using the default values for the relevant arguments in {\tt glmnet()}.

Once $\hat\alpha_j$, $\hat\lambda_j$, and $\hat\tau_j$ are identified for a given partition $j$ of the training data, 
an overall estimate of $\boldsymbol\beta_j$ is obtained by
solving \eqref{eq:penalized_likelihood} for the entire training data set using $\alpha = \hat\alpha_j$ and 
$\lambda = \hat\lambda_j$ 
to obtain $\hat{\boldsymbol\beta}(\hat\lambda_j,\hat\alpha_j)$.  Thus, the LRC obtained using partition $j$ of the 
training data is given by $f \bigl( \mathbf{x},\hat{\boldsymbol{\beta}}(\hat\alpha_j,\hat\lambda_j),\hat\tau_j \bigr)$.  We can
also estimate the risk using the overall parameter estimates by inserting $\hat\alpha_j$, $\hat\lambda_j$, and $\hat\tau_j$ 
into
\eqref{eq:risk} as follows:
\begin{align}
\label{eq:final_risk_j}
R_j  = \frac{1}{N}\sum_{i=1}^N L \Bigl(y_i, f\bigl(\mathbf{x}_i,
\hat{\boldsymbol{\beta}_j}(\hat\alpha_j,\hat\lambda_j), \hat\tau_j \bigr) \Bigr)
\end{align}

If we repeat the entire parameter estimation process for a different random partition, $j^\prime$, of the training data, we
obtain obtain slightly different results.  To ensure the final LRC is robust to the random partitioning process, 
we repeat the training process for multiple partitions, or cross-validation replicates, indexed by $j = 1,\ldots,J$.  
The value of $J$ is controlled by the {\tt cvReps} argument in {\tt LRCglmnet()}.  For each replication, we obtain 
$(\hat\alpha_j, \hat\lambda_j, \hat\tau_j)$, which has a corresponding risk, $R_j$, defined by \eqref{eq:final_risk_j}.  
Calling the {\tt plot()} method
on the object returned by {\tt LRCglmnet()} shows a pairs plot and univariate histogram of the
various $(\hat\alpha_j, \hat\lambda_j, \hat\tau_j)$.  This plot illustrates the consistency of the tuning parameter estimates 
across cross validation replicates.

The final estimate of the tuning parameters is obtained by calculating the median of each one separately:
\begin{align}
(\hat\alpha^\star,\hat\lambda^\star,\hat\tau^\star) = \bigl(\text{median}_j(\hat\alpha_j), \text{median}_j(\hat\lambda_j),
  \text{median}_j(\hat\tau_j) \bigr)
\end{align}
\noindent and then creating the final LRC by fitting all the training data (via \eqref{eq:penalized_likelihood})
with those estimates: 
\begin{align}
f^\star \equiv f \bigl(\mathbf{x},\hat{\boldsymbol{\beta}_j}(\hat\alpha^\star,\hat\lambda^\star), \hat\tau^\star \bigr)
\end{align}
\noindent Calling the {\tt predict()} method on the object returned by {\tt LRCglmnet()} uses $f^\star$ to the classify
new observations.

The overall estimate of the risk, $\bar{R}$, and its standard error, $ is obtained by calulating the mean and standard deviation 
of the $R_j$'s in the usual way:
\begin{align}
\bar{R} = \frac{1}{J}\sum_{j=1}^J R_j & ~~ & \sigma_R = \sqrt{\frac{\sum_{j=1}^J(R_j - \bar{R})^2}{J-1}}
\end{align}





\end{document}
