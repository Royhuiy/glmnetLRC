\documentclass{article}

\usepackage[left=1in, top=1in, right=1in, bottom=1in]{geometry}
\usepackage{graphicx, color}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{url}
\usepackage{float}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{framed}
\usepackage{here}
\usepackage{zi4}
\usepackage{color}
\usepackage{Sweave}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\median}{median}

\renewcommand{\baselinestretch}{1.2}

% \VignetteIndexEntry{lrc Example}

\begin{document} 
\SweaveOpts{concordance=TRUE}

\title{{\tt lrc}: Logistic regression classification (LRC) with an arbitrary loss function\\}
\author{Landon Sego, Alexander Venzin}
\maketitle

\section{Introduction}

The {\tt lrc} package extends the {\tt glmnet} package by making it possible to train elastic net logistic 
regression classifiers (LRC's) using a customized, discrete loss function.  This allows users to assign unique 
loss values to false positive and false negative errors. This approach was originally implemented to automate the
process of determining the curation quality of mass spectrometry samples. Some of the data documented in 
\cite{thepaper} will be used here to demonstrate how to train your own classifier. The elastic net parameter
estimates are obtained by maximizing a penalized likelihood function. The penalty is essentially a weighted average
of the ridge penalty ($L_2$ norm) and the lasso penalty ($L_1$ norm) of the regression parameters.  This
approach balances feature selection and model simplicity. 

In the sections that follow, we show how to use the {\tt lrc} package to train LRC models, create diagnostic plots,
extract coefficients, predict the binary class of new observations, and summarize the performance of those
predictions. The details of the algorithms used by the package are provided in the Appendix.

\section{Training}

Let's begin by loading the package and the training data:
<<data>>==
# Load the package
library(lrc)

# Load the VOrbitrap Shewanella QC data
data(traindata)

# A view of first two rows and first 12 columns
traindata[1:2, 1:12]

# Columns 9 to 96 contain various measures of dataset quality that
# we will use to predict the "Curated_Quality"
predictors <- as.matrix(traindata[,9:96])
@ 

\noindent We fit the LRC model by calling {\tt LRCglmnet()}, which 
requires a binary response variable, coded
as a {\tt factor}.  The order in which the response variable
is coded is important.  Specifically, the class we want to predict with
the greatest sensitivity should be encoded as the second level. To illustrate how this
is done, consider the Shewanella QC data, where the objective is to be
sensitive to predicting poor datasets.  Hence we code ``poor" last, as follows:
<<data1>>=
response <- factor(traindata$Curated_Quality,
                   levels = c("good", "poor"),
                   labels = c("good", "poor"))

levels(response)
@ 
\noindent Now we must define a discrete loss matrix. For the curation
of dataset quality, predicting ``good" when the dataset is ``poor" is considerably 
worse (Loss = 5) than predicting ``poor" when the dataset
is ``good" (Loss = 1).  Correct predictions receive a penalty of zero loss:

<<data2>>=
# Define the loss matrix
lM <- lossMatrix(c("good","good","poor","poor"),
                 c("good","poor","good","poor"),
                 c(     0,     1,     5,     0))

# Observe the structure of the loss matrix
lM
@ 

To train an elastic net model, the user needs to supply a handful of arguments to {\tt LRCglmnet()}. 
The mandatory arguments are the true class labels, {\tt truthLabels} (which, in this case, is, is the {\tt response} 
object we created above), the matrix of predictor variables, {\tt predictors}, 
and the loss matrix {\tt lossMat}. Noteworthy additional arguments include {\tt tauVec}, a vector of potential 
thresholds $\tau \in (0, 1)$ that are used to dichotomize the predicted probabilities from the logistic regression 
into two class labels; {\tt alphaVec}, a vector of potential values of the elastic net mixing parameter 
$\alpha \in [0, 1]$; {\tt cvFolds}, the number of cross validation folds; and {\tt masterSeed}, which controls 
the partitioning the data into the cross validation folds. Keep in mind that $\alpha$ governs the tradeoff between 
the two regularization penalties. When $\alpha = 0$, $L_2$ regularization (the ridge penalty) is used,
and when $\alpha = 1$, $L_1$ regularization (the lasso penality) is used.

Heavier sampling of {\tt tauVec} or {\tt alphaVec} (i.e., sequences of greater length) leads to 
increased computation time, but more of the parameter space will be sampled, potentially leading to a better 
classifier.  We now train the elastic net logistic regression using restricted values of {\tt tauVec} and 
{\tt alphaVec} and a small number of cross validation replicates, {\tt cvReps}.
<<train>>=
# Set the number of cores to be one less than the total available
ncores <- max(1, parallel::detectCores() - 1)

# Fit the LRC model
lrc_fit <- LRCglmnet(response, predictors, lM, nJobs = ncores,
                     cvFolds = 5, cvReps = 2 * ncores,
                     alphaVec = c(1, 0.5), tauVec = c(0.3, 0.5, 0.7),
                     estimateLoss = TRUE)

@ 

\noindent The call to {\tt LRCglmnet()} uses multiple replications of cross validation to solve for 
the optimal tuning parameter settings $\left(\alpha, \lambda, \tau\right)$ that minimize the expected loss for 
the elastic net logistic regression 
classifier. An optimal estimate of the tuning parameters is obtained for each cross validation replicate. 
The final estimate of each tuning parameter is the median value of the optimal estimates from the cross validation replcates.
Printing the object returned by {\tt LRCglmnet()} shows the median value of the optimal tuning parameters over the cross validation 
replicates, as well as the average and standard deviation of the expected loss values calculated for each
cross validation replicate.
 
<<checkdat>>==
print(lrc_fit)
@

\noindent We can also extract the coefficients of the logistic regression model that was created using the 
optimal values of $\alpha$ and $\lambda$ (which were shown by the call to the {\tt print()} method above):
<<getCoef>>==
coef(lrc_fit)
@

\section{Prediction}

Now that the classifier has been properly trained and the optimal parameters have been identified, we are 
interested in making predictions for new data observations. This requires the elastic net regression model 
(the output from {\tt LRCglmnet}) and the set of new observations to be predicted, {\tt newdata}.  
Like other {\tt predict} methods in R, {\tt newdata} must contain columns with names that match the terms 
in the LRC model object (the output of {\tt LRCglmnet()}).  If true labels are available in {\tt newdata}, the column containing 
these true class labels can be specified via the 
{\tt truthCol} argument. Additionally, one may wish to carry through a subset of the explanatory variables in 
{\tt newdata}.  These columns are indicated using {\tt keepCols}.   True labels are not required to make 
predictions---but they are required to compute performance metrics (sensitivity, specificity, etc.) for the 
elastic net logistic regression model. We begin by testing the classifer on the original training data:
<<predictTrain>>=
# Predict the training data
predictTrain <- predict(lrc_fit, traindata, truthCol = "Curated_Quality", keepCols = 1:2)

# Look at beginning of the predicted data.  Note the extra columns that were kept.
head(predictTrain)
@ 
\noindent We can summarize the performance of the classifier predictions with a call to the {\tt summary()} method.
The performance metrics are oriented in terms of being sensitive to predicting a ``poor'' dataset.  Thus, a 
false positive is predicting a dataset is ``poor'' when it is ``good,'' and a false negative is predicting a 
dataset is ``good'' when it is ``poor.''  This orientation results from us setting ``poor'' as the second
level in {\tt response}.
<<summarize>>=
# Summarize the peformance of the new classifier in terms of a variety of metrics:
summary(predictTrain)
@
\noindent Now let's bring in some new data and examine the performance of the classifier:
<<predict>>==
# Load the data for testing
data(testdata)

# Create table observing the true number of good/poor items 
with(testdata, table(Curated_Quality))

# Predict new data
predictTest <- predict(lrc_fit, testdata, truthCol = "Curated_Quality")

# Look at the first few rows
head(predictTest)

# Summarize the output of predicting the data we trained on 
summary(predictTest)
@ 
\noindent If we don't include a truth column in the call to {\tt predict()}, the {\tt summary()} method 
counts the number of observations classified to each category:
<<<summary>>==
summary(predict(lrc_fit, testdata))
@ 


\section{Diagnostics}

\noindent Finally, we would like to get a sense of the distribution of the tuning parameters that were chosen 
during the cross validation phase. The {\tt plot} method produces a $3 \times 3$ scatterplot matrix of the optimal 
triples $\left(\alpha, \lambda, \tau\right)$ associated with the selected regression model from each cross 
validation replicate. The univariate distribution of each parameter is plotted on the diagonal of the 
scatterplot matrix.  Ideally, the distributions of the parameters will be tight over the cross validation 
replicates, indicating that the choice of $\left(\alpha, \lambda, \tau\right)$ is stable regardless of
the particular random partition used for cross validation.

\begin{figure}[H]
\begin{center}
<<plot, fig=TRUE, width=2, height=2>>=
plot(lrc_fit)
@
\caption{Scatterplot matrix of optimal tuning parameters}
\end{center}
\end{figure}

\nocite{*}
\bibliography{lrc}
\bibliographystyle{plain}  

\newpage

\section*{Appendix}
We present in detail the algorithm used by the {\tt lrc} package to identify the optimal parameter estimates
for a logistic regression classifier (LRC) with variables selection implemented by an elastic net.  

We begin by defining a
number of variables.  Let $i = 1,\ldots,N$ index the observations in a training dataset. 
Let $y_i = 1$ indicate that observation $i$ belongs to category ``1" and $y_i = 0$ indicate
that it belongs to category ``0".  Per the logistic regression model, let  
\begin{align}
P(y_i = 1) \equiv \pi_i = \pi(\mathbf{x}_i, \boldsymbol{\beta}) = 
\frac{\exp(\beta_0 + \boldsymbol{\beta}_1^T \mathbf{x}_i)}{1+\exp(\beta_0 + \boldsymbol{\beta}_1^T \mathbf{x}_i)}
\end{align}
\noindent where $\mathbf{x}_i = (x_1, \ldots x_p)^T$ is a vector of predictors, or covariates, that
influence $\pi_i$, $\beta_0$ is an intercept, $\boldsymbol{\beta}_1 = (\beta_1, \ldots, \beta_p)^T$ is a 
vector of  logistic regression coefficients, and for notational convenience, 
$\boldsymbol{\beta} = (\beta_0, \beta_1, \ldots \beta_p)^T$. The estimate of $\boldsymbol{\beta}$ is influenced by 
two other parameters, 
$\alpha$ and $\lambda$.  For this reason, we will often write $\boldsymbol\beta$ as $\boldsymbol\beta(\alpha,\lambda)$.  
The value of $\lambda > 0$ controls the weight of the
penalty of the log-likelihoood function, while $\alpha$ controls the mixture of the ridge and lasso penalties.  
The relationship between $\boldsymbol{\beta}$, $\alpha$, and $\lambda$ will be clarified below.

When we fit the elastic net logistic regression model to the data, we obtain the estimator 
$\hat{\boldsymbol\beta}(\alpha,\lambda)$.  Therefore, 
let $\hat\pi_i \equiv \pi \bigl( \mathbf{x}_i,\hat{\boldsymbol\beta}(\alpha,\lambda) \bigr)$ denote the predicted probability 
that $y_i = 1$.  Then, if $\hat\pi_i > \tau$, where $0 < \tau < 1$, the LRC predicts 
that $y_i = 1$.  It will be useful to represent the predicted class of observation
$i$ as $\hat{y}_i \equiv f \bigl( \mathbf{x}_i,\hat{\boldsymbol{\beta}}(\alpha,\lambda),\tau \bigr) = 
I_{(\hat\pi_i > \tau)}$, where $f$ can be thought of as the LRC.

For the elastic net, the estimate $\hat{\boldsymbol{\beta}}$ is the $\boldsymbol{\beta}$
that maximizes the penalized log likelihood function:
\begin{align}
\label{eq:penalized_likelihood}
\hat{\boldsymbol{\beta}}(\alpha,\lambda) = \argmax_{\boldsymbol{\beta}} \Biggl[ \ell(\mathbf{x}_i,\boldsymbol{\beta}) - \lambda 
\biggl( \frac{1-\alpha}{2} \sum_{i=1}^p \beta_i^2 + \alpha \sum_{i=1}^p |\beta_i| \biggr) \Biggr]
\end{align}
\noindent where the unpenalized likelihood is given by
\begin{align}
\ell(\mathbf{x}_i,\boldsymbol{\beta}) = \sum_{i=1}^N \bigl[ y_i \log(\pi_i) + (1 - y_i)\log(1-\pi_i) \bigr]
\end{align}
\noindent Parenthetically, $\alpha = 1$ is the lasso penalty, $\alpha = 0$ is the ridge regression penalty,
and $0 < \alpha < 1$ is a mixture of the two. The penalty in \eqref{eq:penalized_likelihood} is the one
specified in the documentation of {\tt glmnet()} in the {\tt glmnet} package.

The optimal values of the tuning parameters, $\alpha$, $\lambda$, and $\tau$, are obtained by minimizing 
the risk, or expected loss, of 
the LRC, where the risk is calculated via cross validation.  Calculating risk requires that we define a discrete 
loss function, $L(y,\hat{y})$ as follows:
\begin{table}[H]
\begin{center}
\begin{tabular}{c|cc}
& $\hat{y} = 0$ & $\hat{y} = 1$ \\
\hline
$y = 0$ & $0$ & $\kappa_0$ \\
$y = 1$ & $\kappa_1$ & $0$ \\
\end{tabular}
\end{center}
\end{table}
\noindent with $\kappa_0 > 0$ and $\kappa_1 > 0$ chosen to reflect the severity of false-positive and 
false-negative errors, respectively.  Setting $\kappa_0 = \kappa_1 = 1$ results in the commonly used 0-1 loss
function.  In the {\tt lrc} package, $L$ is specified via a call to {\tt lossMatrix()}, and the result is passed to
the {\tt lossMatt} argument of {\tt LRCglmnet()}.

Cross validation is accomplished by randomly partitioning the training data into $m$ folds (non-overlapping and
exhaustive subsets) of the training data. The value of $m$ is controlled by the {\tt cvFolds} argument in 
{\tt LRCglmnet()}. Following the presentation of Hastie et al. \cite{Hastie}, let
\begin{align}
\delta:\{1,\ldots,N\} \rightarrow \{1, \ldots, m\}
\end{align}
\noindent map each observation in the training data to one of the folds.
Let $f^{-k} \bigl( \mathbf{x},\hat{\boldsymbol{\beta}}(\alpha,\lambda),\tau \bigr)$ represent the LRC obtained by estimating 
$\boldsymbol{\beta}$ using all the training data except the $k^{\text{th}}$ fold. The 
cross validation estimate of the risk is given by
\begin{align}
\label{eq:risk}
R(\alpha,\lambda,\tau) = \frac{1}{N}\sum_{i=1}^N L \Bigl(y_i, f^{-\delta(i)} \bigl(\mathbf{x}_i,
\hat{\boldsymbol{\beta}}(\alpha,\lambda),\tau \bigr) \Bigr)
\end{align}
\noindent Note that \eqref{eq:risk} is defined such that each observation in the training data receives 
equal weight. The optimal estimates of the tuning parameters are those that minimize the risk:
\begin{align}
(\hat\alpha,\hat\lambda,\hat\tau) = \argmin_{\alpha,\lambda,\tau} R(\alpha,\lambda,\tau)
\end{align}
In practice, we calculate $(\hat\alpha$, $\hat\lambda$, $\hat\tau)$ by computing \eqref{eq:risk} over an irregular
cube of discrete parameter values, defined by the combination of three vectors:  
$\boldsymbol\alpha \times \boldsymbol\lambda \times \boldsymbol\tau$.
The point in the cube that minimizes the risk becomes the estimate for $(\alpha, \lambda, \tau)$.
The values of $\boldsymbol\alpha$ and $\boldsymbol\tau$ are specified by the {\tt alphaVec} and {\tt tauVec} arguments
of {\tt LRCglmnet()}, respectively.  The values of $\boldsymbol\lambda$ depend on each $\alpha$ and are chosen algorithmically
by {\tt glmnet()}, using the default values for the relevant arguments in {\tt glmnet()}.

So far in this discussion, we have made reference to a single random partition of the training data into $m$ folds.  However,
the estimates of the tuning parameters will depend on the partition. To ensure the final LRC is robust to the random 
partitioning process, we repeat the training process for multiple partitions, or cross validation replicates, 
indexed by $j = 1,\ldots,J$.  The value of $J$ is controlled by the {\tt cvReps} argument in {\tt LRCglmnet()}.

Once $\hat\alpha_j$, $\hat\lambda_j$, and $\hat\tau_j$ are identified for partition $j$ of the training data, 
an overall estimate of $\boldsymbol\beta_j$ is obtained by
solving \eqref{eq:penalized_likelihood} for the entire training data set using $\alpha = \hat\alpha_j$ and $\lambda = \hat\lambda_j$ 
to obtain $\hat{\boldsymbol\beta}(\hat\alpha_j,\hat\lambda_j)$.  The LRC obtained using partition $j$ of the
training data is given by $f \bigl( \mathbf{x},\hat{\boldsymbol{\beta}}(\hat\alpha_j,\hat\lambda_j),\hat\tau_j \bigr)$.  We can
also estimate the risk using the overall parameter estimates by inserting $\hat\alpha_j$, $\hat\lambda_j$, and $\hat\tau_j$ 
into
\eqref{eq:risk} as follows:
\begin{align}
\label{eq:final_risk_j}
R_j  = \frac{1}{N}\sum_{i=1}^N L \Bigl(y_i, f\bigl(\mathbf{x}_i,
\hat{\boldsymbol{\beta}}(\hat\alpha_j,\hat\lambda_j), \hat\tau_j \bigr) \Bigr)
\end{align}

Thus, for each cross validation replicate, we obtain 
$(\hat\alpha_j, \hat\lambda_j, \hat\tau_j)$, which has a corresponding $\hat{\boldsymbol\beta}(\hat\alpha_j,\hat\lambda_j)$ 
and risk estimate, $R_j$. Calling the {\tt plot()} method
on the object returned by {\tt LRCglmnet()} shows a pairs plot and univariate histogram of the
various $(\hat\alpha_j, \hat\lambda_j, \hat\tau_j)$.  This plot illustrates the consistency of the tuning parameter estimates 
across cross validation replicates.

The final estimate of the tuning parameters is obtained by calculating the median of each one separately:
\begin{align}
\label{eq:final_tuning}
(\hat\alpha^\star,\hat\lambda^\star,\hat\tau^\star) = \bigl(\median_j(\hat\alpha_j), ~\median_j(\hat\lambda_j),
  ~\median_j(\hat\tau_j) \bigr)
\end{align}
\noindent and then creating the final estimate of $\boldsymbol\beta$ by fitting all the training 
data (via \eqref{eq:penalized_likelihood}) using the final estimates of the tuning parameters \eqref{eq:final_tuning}, 
which gives rise to the final LRC:
\begin{align}
f^\star \equiv f \bigl(\mathbf{x},\hat{\boldsymbol{\beta}}(\hat\alpha^\star,\hat\lambda^\star), \hat\tau^\star \bigr)
\end{align}
\noindent Calling the {\tt predict()} method on the object returned by {\tt LRCglmnet()} uses $f^\star$ to classify
new observations.  Likewise, calling the {\tt coef()} method on the object returned by {\tt LRCglmnet()} returns 
$\hat{\boldsymbol\beta}(\hat\alpha^\star,\hat\lambda^\star)$.

The overall estimate of the risk, $\bar{R}$, and its standard deviation, $\sigma_R$, is obtained by calculating 
the mean and standard deviation of the $R_j$'s in the usual way:
\begin{align}
\bar{R} = \frac{1}{J}\sum_{j=1}^J R_j,  ~~~~ \sigma_R = \sqrt{\frac{\sum_{j=1}^J(R_j - \bar{R})^2}{J-1}}
\end{align}
The values of $\bar{R}$ and $\sigma_R$ are obtained by calling {\tt LRCglmnet()} with the argument {\tt estimateLoss = TRUE}
and then printing the resulting object.

\end{document}
